{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressaoSoftmaxNewton2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbrunonascimento/IME/blob/main/RegressaoSoftmaxNewton2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpNAD6pC-aja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52kdaF32yDor"
      },
      "source": [
        "**Atividade 2**\n",
        "\n",
        "\n",
        "\n",
        "- Andréa Longarini - 11112600\n",
        "- Augusto Cezar Garcia Lozano - 12496820\n",
        "- Bruno Gonçalves Dias - 12099900\n",
        "- Diego Bruno dos Santos do Nascimento - 11562547\n",
        "- Henrique Douglas da Silva - 13047692\n",
        "- Renato Banzai - 3683321"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wslMfENdMWp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs4z8laf_ej2"
      },
      "source": [
        "# dados de treino\n",
        "columns = [\"atrib1\", \"atrib2\", \"atrib3\", \"atrib4\", \"class\"]\n",
        "df = pd.read_csv('./dataset_train.txt', delimiter = \"\\t\")\n",
        "df.columns = columns\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPtb2IFJ-ec3"
      },
      "source": [
        "# dados de teste \n",
        "df_test = pd.read_csv('./dataset_teste.txt', delimiter = \"\\t\")\n",
        "df_test.columns = columns\n",
        "df_test.head()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0IH3uY0-kjy"
      },
      "source": [
        "# Selecao das caracteristicas dos dados de treino\n",
        "features = df[[\"atrib1\", \"atrib2\", \"atrib3\", \"atrib4\"]] \n",
        "features = features.to_numpy() \n",
        "target = df['class'].to_numpy()\n",
        "\n",
        "target_on_hot = np.array([[int(x==1), int(x==2), int(x==3)] for x in target])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O56WAfHMnuRx"
      },
      "source": [
        "#  Selecao das caracteristicas dos dados de teste\n",
        "features_test = df_test[[\"atrib1\", \"atrib2\", \"atrib3\", \"atrib4\"]] \n",
        "features_test = features_test.to_numpy() # converts feature set to numpy array\n",
        "target_test = df_test['class'].to_numpy() # converts target column to numpy array\n",
        "\n",
        "target_on_hot_test = np.array([[int(x==1), int(x==2), int(x==3)] for x in target_test])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjBFBJUj_Vvv"
      },
      "source": [
        "# Padrão Escalar\n",
        "def standardScaler(feature_array):\n",
        "    \n",
        "    total_cols = feature_array.shape[1] # numero de colunas \n",
        "    \n",
        "    for i in range(total_cols): \n",
        "        feature_col = feature_array[:, i]\n",
        "        \n",
        "        mean = feature_col.mean() # mean stores mean value for the column\n",
        "        std = feature_col.std() # std stores standard deviation value for the column \n",
        "        feature_array[:, i] = (feature_array[:, i] - mean) / std # standard scaling of each element of the column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmfO0EyoGxdR"
      },
      "source": [
        "\n",
        "standardScaler(features)\n",
        "# features  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzXWziD9oNW7"
      },
      "source": [
        "standardScaler(features_test)\n",
        "# features_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzPCcp4EjIhN"
      },
      "source": [
        "def softmax(x):\n",
        "    num = np.exp(x)\n",
        "    denum = np.sum(np.exp(x))\n",
        "    final = num/denum \n",
        "    return final "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxTCLWspmBob"
      },
      "source": [
        "# creating randomized weights for our linear predictor func\n",
        "weights = np.random.rand(target_on_hot.shape[1], features.shape[1]+1)\n",
        "ones = np.ones(len(features))\n",
        "features_w = np.c_[ones, features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tadd8dEsRXma",
        "outputId": "33583a71-1d7e-494b-9b03-559178458f6b"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.82712248, 0.98289453, 0.70057852, 0.60733647, 0.86386316],\n",
              "       [0.79346173, 0.19654172, 0.71972345, 0.9527923 , 0.85177473],\n",
              "       [0.08114018, 0.84157865, 0.87908636, 0.66997386, 0.06927273]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2HvzBt2xure"
      },
      "source": [
        "learning_rate= 0.01\n",
        "\n",
        "def gradient(features_w, y, target_on_hot ): \n",
        "    return learning_rate * - (y-target_on_hot).T.dot(features_w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeU-S39zZa4q"
      },
      "source": [
        "def cross_entropy(output, target_on_hot):\n",
        "    return -np.sum(np.log(output) * (target_on_hot), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6P8rSOO3ymU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nevWcSM3pWCw"
      },
      "source": [
        "maxInt = 40\n",
        "cost = []\n",
        "\n",
        "for it in range(maxInt):\n",
        "    sW = np.matmul(features_w, weights.T)\n",
        "  \n",
        "    s2 = []\n",
        "    for l  in sW:\n",
        "      s2.append(softmax(l))\n",
        "\n",
        "    y = np.array(s2) \n",
        "\n",
        "    # temp_y = []\n",
        "    # for linha  in s:\n",
        "    #   m = max(linha)\n",
        "    #   x  =  np.where(linha == m)[0][0]\n",
        "    #   temp_y.append([int(x==0), int(x==1), int(x==2)])\n",
        "    #np.array(temp_y) \n",
        "\n",
        "    # print('cross_entropy-->', y, target_on_hot,  cross_entropy(y, target_on_hot)) \n",
        "\n",
        "    cost.append(np.mean(cross_entropy(y, target_on_hot)))\n",
        "\n",
        "    print('y:', it,  np.sum(y[:,0]), np.sum(y[:,1]), np.sum(y[:,2]))\n",
        "  \n",
        "    weights = weights + gradient(features_w, y, target_on_hot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZV-vLwZTF9g"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(cost)), cost)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp5zB_rNFn-H"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkFbT-zhNFjy"
      },
      "source": [
        "Método de Newton "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lktYeZjnFAKe"
      },
      "source": [
        "x = features_w\n",
        "weights = np.random.rand(target_on_hot.shape[1], features.shape[1]+1)\n",
        "\n",
        "Yr1 = np.matmul(x, weights.T)\n",
        "\n",
        "s2 = []\n",
        "for l in Yr1:\n",
        "  s2.append(softmax(l))\n",
        "\n",
        "Yr = np.array(s2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpY-AekTNgZG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Sjf9rnIDuZ"
      },
      "source": [
        "N = len(features) # quantidade de amostras\n",
        "k = 1  # indices \n",
        "ns = 3 # numero de classes\n",
        "ne = 4 # numero de entradas\n",
        "\n",
        "dJ = np.zeros([ne*ns,ne*ns]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb4n67UVOXKE"
      },
      "source": [
        "for n in range(N): \n",
        "  lin = 0\n",
        "  col = 0 \n",
        "  for k in range(1, ns): # linhas \n",
        "     for m in range(1, ne+1): \n",
        "       lin = lin + 1\n",
        "       col = 0    \n",
        "       for i in range(1, ns):\n",
        "         for j in range(1, ne+1): #colunas\n",
        "            col = col + 1   \n",
        "            if k == i:           \n",
        "                delta = 1\n",
        "            else: \n",
        "                delta = 0 \n",
        "            dJ[lin, col] = dJ[lin, col] - x[n,j] * (delta-y[n,i]) * y[n,k] * x[n,m]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUkw1bwignec"
      },
      "source": [
        "dJ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLafCjswU2Eq"
      },
      "source": [
        "from numpy.linalg import inv, eig\n",
        "\n",
        "def check_cond(H, ne, ns): \n",
        "  \n",
        "  D, V = eig(H)\n",
        "  D = np.min(D)\n",
        "\n",
        "  i = 0\n",
        "  maxIt = 400\n",
        "\n",
        "  while D < 0.01:\n",
        "    i = i + 1 \n",
        "    H = H + (0.01 * np.eye(ne*ns))\n",
        "    D, V = eig(H)\n",
        "    D = np.min(D)\n",
        " \n",
        "  return H \n",
        "\n",
        "H = check_cond(dJ,ne,ns)\n",
        "\n",
        "inv(H)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5huw65Vl_RO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}